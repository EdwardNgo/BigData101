{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eligible-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comprehensive-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.appName(\"data-types\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lyric-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/viethoang/petproject/20202/BigData101/data/retail.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lasting-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "future-collins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exposed-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[5: int, five: string, 5.0: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert native type to spark type\n",
    "from pyspark.sql.functions import lit\n",
    "df.select(lit(5),lit(\"five\"),lit(5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stupid-termination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.where(col(\"InvoiceNo\") != 536365)\\\n",
    ".select(\"InvoiceNo\", \"Description\")\\\n",
    ".show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-basis",
   "metadata": {},
   "source": [
    "### Working with string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "photographic-abraham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|initcap(Description)|\n",
      "+--------------------+\n",
      "|White Hanging Hea...|\n",
      "| White Metal Lantern|\n",
      "|Cream Cupid Heart...|\n",
      "|Knitted Union Fla...|\n",
      "|Red Woolly Hottie...|\n",
      "|Set 7 Babushka Ne...|\n",
      "|Glass Star Froste...|\n",
      "|Hand Warmer Union...|\n",
      "|Hand Warmer Red P...|\n",
      "|Assorted Colour B...|\n",
      "|Poppy's Playhouse...|\n",
      "|Poppy's Playhouse...|\n",
      "|Feltcraft Princes...|\n",
      "|Ivory Knitted Mug...|\n",
      "|Box Of 6 Assorted...|\n",
      "|Box Of Vintage Ji...|\n",
      "|Box Of Vintage Al...|\n",
      "|Home Building Blo...|\n",
      "|Love Building Blo...|\n",
      "|Recipe Box With M...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in Python\n",
    "from pyspark.sql.functions import initcap\n",
    "df.select(initcap(col(\"Description\"))).show()#viet hoa chu cai dau tien cua moi tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "million-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----+---+----------+\n",
      "|   ltrim|    rtrim| trim| lp|        rp|\n",
      "+--------+---------+-----+---+----------+\n",
      "|HELLO   |    HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO   |    HELLO|HELLO|HEL|HELLO     |\n",
      "+--------+---------+-----+---+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
    "df.select(\n",
    "ltrim(lit(\"    HELLO   \")).alias(\"ltrim\"),\n",
    "rtrim(lit(\"    HELLO   \")).alias(\"rtrim\"),\n",
    "trim(lit(\"     HELLO   \")).alias(\"trim\"),\n",
    "lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
    "rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "distributed-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         color_clean|         Description|\n",
      "+--------------------+--------------------+\n",
      "|COLOR HANGING HEA...|WHITE HANGING HEA...|\n",
      "| COLOR METAL LANTERN| WHITE METAL LANTERN|\n",
      "|CREAM CUPID HEART...|CREAM CUPID HEART...|\n",
      "|KNITTED UNION FLA...|KNITTED UNION FLA...|\n",
      "|COLOR WOOLLY HOTT...|RED WOOLLY HOTTIE...|\n",
      "|SET 7 BABUSHKA NE...|SET 7 BABUSHKA NE...|\n",
      "|GLASS STAR FROSTE...|GLASS STAR FROSTE...|\n",
      "|HAND WARMER UNION...|HAND WARMER UNION...|\n",
      "|HAND WARMER COLOR...|HAND WARMER RED P...|\n",
      "|ASSORTED COLOUR B...|ASSORTED COLOUR B...|\n",
      "|POPPY'S PLAYHOUSE...|POPPY'S PLAYHOUSE...|\n",
      "|POPPY'S PLAYHOUSE...|POPPY'S PLAYHOUSE...|\n",
      "|FELTCRAFT PRINCES...|FELTCRAFT PRINCES...|\n",
      "|IVORY KNITTED MUG...|IVORY KNITTED MUG...|\n",
      "|BOX OF 6 ASSORTED...|BOX OF 6 ASSORTED...|\n",
      "|BOX OF VINTAGE JI...|BOX OF VINTAGE JI...|\n",
      "|BOX OF VINTAGE AL...|BOX OF VINTAGE AL...|\n",
      "|HOME BUILDING BLO...|HOME BUILDING BLO...|\n",
      "|LOVE BUILDING BLO...|LOVE BUILDING BLO...|\n",
      "|RECIPE BOX WITH M...|RECIPE BOX WITH M...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Regex\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "regex_string = \"RED|WHITE|BLACK|BLUE\"\n",
    "df.select(regexp_replace(col(\"Description\"),regex_string,\"COLOR\").alias(\"color_clean\"),col(\"Description\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "romance-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------+\n",
      "|translate(Description, LEET, 1337)|         Description|\n",
      "+----------------------------------+--------------------+\n",
      "|              WHI73 HANGING H3A...|WHITE HANGING HEA...|\n",
      "|               WHI73 M37A1 1AN73RN| WHITE METAL LANTERN|\n",
      "+----------------------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import translate\n",
    "df.select(translate(col(\"Description\"), \"LEET\", \"1337\"),col(\"Description\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "compressed-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with Datetime\n",
    "from pyspark.sql.functions import current_date, current_timestamp,date_add,date_sub\n",
    "dateDF = sc.range(10)\\\n",
    ".withColumn(\"today\", current_date())\\\n",
    ".withColumn(\"now\", current_timestamp())\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "indie-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2021-05-26|        2021-06-05|\n",
      "+------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(date_sub(col(\"today\"), 5), date_add(col(\"today\"), 5)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "noble-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                    -16.67741935|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff, months_between, to_date\n",
    "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
    ".select(datediff(col(\"week_ago\"), col(\"today\"))).show(1)\n",
    "dateDF.select(\n",
    "to_date(lit(\"2016-01-01\")).alias(\"start\"),\n",
    "to_date(lit(\"2017-05-22\")).alias(\"end\"))\\\n",
    ".select(months_between(col(\"start\"), col(\"end\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "completed-independence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date|     date2|\n",
      "+----------+----------+\n",
      "|2017-11-12|2017-12-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "dateFormat = \"yyyy-dd-MM\"\n",
    "cleanDateDF = sc.range(1).select(\n",
    "to_date(lit(\"2017-12-11\"), dateFormat).alias(\"date\"),\n",
    "to_date(lit(\"2017-20-12\"), dateFormat).alias(\"date2\"))\n",
    "cleanDateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the first non-null value from a set of columns\n",
    "from pyspark.sql.functions import coalesce\n",
    "df.select(coalesce(col(\"Description\"), col(\"CustomerId\"))).show()\n",
    "#may cái null,na này vẫn giống trong pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-referral",
   "metadata": {},
   "source": [
    "### Working with complex types\n",
    "* Struct\n",
    "* Array\n",
    "* Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "spatial-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Struct\n",
    "from pyspark.sql.functions import struct\n",
    "complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "coated-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|complex                                      |\n",
      "+---------------------------------------------+\n",
      "|{WHITE HANGING HEART T-LIGHT HOLDER, 536365} |\n",
      "|{WHITE METAL LANTERN, 536365}                |\n",
      "|{CREAM CUPID HEARTS COAT HANGER, 536365}     |\n",
      "|{KNITTED UNION FLAG HOT WATER BOTTLE, 536365}|\n",
      "|{RED WOOLLY HOTTIE WHITE HEART., 536365}     |\n",
      "+---------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------------------------+\n",
      "|complex.Description                |\n",
      "+-----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER |\n",
      "|WHITE METAL LANTERN                |\n",
      "|CREAM CUPID HEARTS COAT HANGER     |\n",
      "|KNITTED UNION FLAG HOT WATER BOTTLE|\n",
      "|RED WOOLLY HOTTIE WHITE HEART.     |\n",
      "+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.show(5,False)\n",
    "complexDF.select(col(\"complex\").getField(\"Description\")).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "annoying-hearts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|split(Description,  , -1)               |\n",
      "+----------------------------------------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|\n",
      "|[WHITE, METAL, LANTERN]                 |\n",
      "+----------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------------+\n",
      "|array_col[0]|\n",
      "+------------+\n",
      "|       WHITE|\n",
      "|       WHITE|\n",
      "+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Array and its function\n",
    "#Split\n",
    "from pyspark.sql.functions import split\n",
    "df.select(split(col(\"Description\"), \" \")).show(2,False)\n",
    "df.select(split(col(\"Description\"), \" \").alias(\"array_col\"))\\\n",
    ".selectExpr(\"array_col[0]\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "demographic-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Array contains test*******\n",
      "+------------------------------------------------+\n",
      "|array_contains(split(Description,  , -1), WHITE)|\n",
      "+------------------------------------------------+\n",
      "|                                            true|\n",
      "|                                            true|\n",
      "+------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#array length\n",
    "#array_contains\n",
    "print(\"******Array contains test*******\")\n",
    "from pyspark.sql.functions import array_contains\n",
    "df.select(array_contains(split(col(\"Description\"), \" \"), \"WHITE\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "comprehensive-grade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+---------+--------+\n",
      "|Description                       |InvoiceNo|exploded|\n",
      "+----------------------------------+---------+--------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|536365   |WHITE   |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|536365   |HANGING |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|536365   |HEART   |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|536365   |T-LIGHT |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|536365   |HOLDER  |\n",
      "|WHITE METAL LANTERN               |536365   |WHITE   |\n",
      "|WHITE METAL LANTERN               |536365   |METAL   |\n",
      "|WHITE METAL LANTERN               |536365   |LANTERN |\n",
      "|CREAM CUPID HEARTS COAT HANGER    |536365   |CREAM   |\n",
      "|CREAM CUPID HEARTS COAT HANGER    |536365   |CUPID   |\n",
      "+----------------------------------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The explode function takes a column that consists of arrays and creates one row \n",
    "# (with the rest of the values duplicated)\n",
    "from pyspark.sql.functions import split, explode\n",
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
    ".withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
    ".select(\"Description\", \"InvoiceNo\", \"exploded\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "acute-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         complex_map|\n",
      "+--------------------+\n",
      "|{WHITE HANGING HE...|\n",
      "|{WHITE METAL LANT...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------------------+\n",
      "|complex_map[WHITE METAL LANTERN]|\n",
      "+--------------------------------+\n",
      "|                            null|\n",
      "|                          536365|\n",
      "+--------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Map\n",
    "from pyspark.sql.functions import create_map,col\n",
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\\\n",
    ".show(2)\n",
    "#select as key-value\n",
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\\\n",
    "  .selectExpr(\"complex_map['WHITE METAL LANTERN']\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ceramic-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   to_json(myStruct)|\n",
      "+--------------------+\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "|{\"InvoiceNo\":\"536...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#json\n",
    "from pyspark.sql.functions import to_json\n",
    "df.selectExpr(\"(InvoiceNo, Description) as myStruct\")\\\n",
    ".select(to_json(col(\"myStruct\"))).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdataenv",
   "language": "python",
   "name": "bigdataenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
